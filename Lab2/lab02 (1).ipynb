{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gY-Z4kKG_DKz"
   },
   "source": [
    "# AI and Blockchain: Fall 2023\n",
    "## Lab 02 : Secure and Private AI \n",
    "\n",
    "<p><b>Instructions:</b> Complete the code in the designated cells, and upload the completed python notebook on LMS prefixed with your RCS ID, i.e., \"senevo_lab02.ipynb\". </p>\n",
    "\n",
    "<p>Total points: <b>100</b></p>\n",
    "\n",
    "<p>Assigned: <b>Oct 6, 2023</b></p>\n",
    "<p>Due: <b>9:59 AM Oct 20, 2023</b></p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Please Type Your Information\n",
    "\n",
    "RCS ID: \n",
    "\n",
    "Name: \n",
    "\n",
    "Level (4000/6000): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlmjxhWcGFKe"
   },
   "source": [
    "## Differential Privacy with a Toy Dataset\n",
    "\n",
    "Step one is to create our dataset, i.e., \"database\" - we will do this by initializing a random list of 1s and 0s (the entries in our database). Note - the number of entries directly corresponds to the number of people in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "29sKX2k0DQ2y",
    "outputId": "bf3efde6-6350-44f7-d327-ee6cd7d0d2da"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "num_entries = 5000\n",
    "db = torch.rand(5000) > 0.5\n",
    "db.int()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PzzzOF6hJP2L",
    "outputId": "94346801-b98d-4488-9f11-9df661bd7608"
   },
   "outputs": [],
   "source": [
    "db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CYNCtHwGWEF"
   },
   "source": [
    "Key to the definition of differential privacy is the ability to ask the question, \"When querying a database if I removed someone from the database, would the output of the query be any different?\". To check this, we must construct what we term \"parallel databases,\" which are simply databases with one entry removed.\n",
    "\n",
    "### Task 1: Create parallel databases (2 points)\n",
    "\n",
    "Create a list of every parallel database to the one currently in the \"db\" variable. The code to create a single parallel database is provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLGzhm2XG0dy"
   },
   "outputs": [],
   "source": [
    "def get_parallel_db(db, remove_index):\n",
    "\n",
    "    return torch.cat((db[0:remove_index], \n",
    "                      db[remove_index+1:]))\n",
    "                      \n",
    "def get_parallel_dbs(db):\n",
    "    parallel_dbs = list()\n",
    "    \n",
    "    # Type your code here\n",
    "    \n",
    "    return parallel_dbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the database and the parallels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwAb4_8aIIa_"
   },
   "outputs": [],
   "source": [
    "def create_db_and_parallels(num_entries):\n",
    "    \n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    \n",
    "    return db, pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V87lcvnskkHk"
   },
   "source": [
    "## Evaluating The Differential Privacy of a Function\n",
    "\n",
    "Let's make our first \"database query\" a simple sum by counting the number of 1s in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmVkLlqfk63j"
   },
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallels(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfITf2mUlF-B"
   },
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fyBWU-PFlIba",
    "outputId": "73cf4a64-6496-40c4-f311-89cd6b320ac5"
   },
   "outputs": [],
   "source": [
    "full_db_result = query(db)\n",
    "full_db_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1bgsCBW6m6_X",
    "outputId": "5d6f46b2-544d-4862-a21b-6358ccb2d2a2"
   },
   "outputs": [],
   "source": [
    "pdb0_result = query(pdbs[0])\n",
    "pdb0_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHqgQMhflLOv"
   },
   "outputs": [],
   "source": [
    "sensitivity = 0\n",
    "for pdb in pdbs:\n",
    "    pdb_result = query(pdb)\n",
    "    \n",
    "    db_distance = torch.abs(pdb_result - full_db_result)\n",
    "    \n",
    "    if(db_distance > sensitivity):\n",
    "        sensitivity = db_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sxYYVjOilNG5",
    "outputId": "50750935-9152-4cc7-d32d-9665cb3e3370"
   },
   "outputs": [],
   "source": [
    "sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gPWNoKip_A6"
   },
   "source": [
    "## Evaluating the Privacy of a Function\n",
    "\n",
    "We can measure the difference between each parallel db's query result and the query result for the entire database by calculating the max value (1). This value is called \"sensitivity,\" corresponding to the function we chose for the query. The \"sum\" query will always have a sensitivity of exactly 1. We can also calculate sensitivity for other functions. The steps for evaluating the sensitivity include the following:\n",
    "\n",
    "* Initialize a database of the correct size\n",
    "* Initialize all parallel databases\n",
    "* Run the query over all databases\n",
    "* Correctly calculate sensitivity\n",
    "* Return the sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRdhVoQ07utx"
   },
   "outputs": [],
   "source": [
    "def sensitivity(query, n_entries=1000):\n",
    "\n",
    "    db, pdbs = create_db_and_parallels(n_entries)\n",
    "    \n",
    "    full_db_result = query(db)\n",
    "    \n",
    "    max_distance = 0\n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "\n",
    "        if(db_distance > max_distance):\n",
    "            max_distance = db_distance\n",
    "            \n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ke_-72Dp8KnP"
   },
   "source": [
    "### Task 2: Calculate sensitivity for the \"mean\" function (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here. You should print the sensitivity for mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FnSEmL8n-8T1"
   },
   "source": [
    "## A Basic Differencing Attack\n",
    "\n",
    "Let's construct a database and then demonstrate how you can use two different sum queries to expose the value of the person represented by row 10 in the database (note, you'll need to use a database with at least 10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGijuH4pE7PO"
   },
   "outputs": [],
   "source": [
    "db, _ = create_db_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aByBBoKE_ay"
   },
   "outputs": [],
   "source": [
    "pdb = get_parallel_db(db, remove_index=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MVB4BXCCFBK0",
    "outputId": "96a53e04-5c0a-4f1e-ba81-cd30871300de"
   },
   "outputs": [],
   "source": [
    "db[10].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dj7ZUny3FCys",
    "outputId": "14548bd8-3445-4167-95a8-e2c2ec7e68ff"
   },
   "outputs": [],
   "source": [
    "sum(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0XGBTYB5FGRS",
    "outputId": "51a3ffcb-6ccf-4eae-9f56-805b1ba1f88c"
   },
   "outputs": [],
   "source": [
    "# differencing attack using sum query\n",
    "sum(db) - sum(pdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Demonstrate the differencing attack using the mean query (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VxuCC4vIFKjK",
    "outputId": "27c1814a-5ff2-4417-d9e0-8c41e0dd5502"
   },
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kprAlJYHFR2"
   },
   "source": [
    "## Local Differential Privacy\n",
    "### Randomized Response\n",
    "\n",
    "Let's say we have a group of people we wish to survey about a taboo behavior (e.g., nose picking, drug addiction, criminal behavior, cheating on their spouse) that we think they will lie about. \n",
    "We are not law enforcement; we are just trying to collect statistics to understand the higher-level trend in society using AI. \n",
    "So, how do we do this?\n",
    "\n",
    "One technique is to add randomness to each person's response by giving each person the following instructions (assuming we are asking a simple yes/no question):\n",
    "\n",
    "* Flip a coin two times.\n",
    "* If the first coin flip is heads, answer honestly\n",
    "* If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)!\n",
    "\n",
    "Each person is now protected with \"plausible deniability.\" If they answer \"Yes\" to the question \"Have you committed X crime?\", it might be because they actually did or because they are answering according to a random coin flip. Each person has a high degree of protection. Furthermore, we can recover the underlying statistics with some accuracy, as the \"true statistics\" are averaged with a 50% probability. Thus, if we collect a bunch of samples and it turns out that 60% of people answer yes, then we know that the TRUE distribution is centered around 70% because 70% averaged with 50% (a coin flip) is 60%, which is the result we obtained.\n",
    "\n",
    "However, it should be noted that, especially when we only have a few samples, this comes at the cost of accuracy. This tradeoff exists across all of Differential Privacy. The greater the privacy protection (plausible deniability), the less accurate the results.\n",
    "\n",
    "Let's implement this local DP for our database before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTrLAJjHRHMx"
   },
   "outputs": [],
   "source": [
    "def query(db):\n",
    "\n",
    "    true_result = torch.mean(db.float())\n",
    "    \n",
    "    first_coin_flip = (torch.rand(len(db)) < 0.5).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) < 0.5).float()\n",
    "\n",
    "    augmented_database = db.float() * first_coin_flip + (1 - first_coin_flip) * second_coin_flip\n",
    "\n",
    "    private_result = torch.mean(augmented_database.float()) * 2 - 0.5\n",
    "    \n",
    "    return private_result, true_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoECjzMldKtR"
   },
   "source": [
    "### Task 4: Show how the private result (with noise) and the true result (without noise) change for databases of size 10, 100, 1000, and 10000. (5 points)\n",
    "*Hint: Chart the results in a histogram for easy comparison.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWBAzQfx7CI4"
   },
   "source": [
    "## Varying Amounts of Noise\n",
    "\n",
    "Let's augment the randomized response query (the one we just wrote) to allow for varying amounts of randomness to be added. Specifically, let's bias the coin flip to be higher or lower and then run the same experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySYXrNtf7RbN"
   },
   "outputs": [],
   "source": [
    "def query(db, noise=0.2):\n",
    "    \n",
    "    true_result = torch.mean(db.float())\n",
    "\n",
    "    first_coin_flip = (torch.rand(len(db)) < noise).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) < 0.5).float()\n",
    "\n",
    "    augmented_database = db.float() * first_coin_flip + (1 - first_coin_flip) * second_coin_flip\n",
    "\n",
    "    sk_result = augmented_database.float().mean()\n",
    "\n",
    "    private_result = ((sk_result / noise) - 0.5) * noise / (1 - noise)\n",
    "\n",
    "    return private_result, true_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3a4YrQey7Wzc"
   },
   "source": [
    "### Task 5: Show how the private result (with noise) and the true result (without noise) changes for databases of size 10, 100, 1000, and 10000 with varying noise levels (noise=[0.1, 0.2, ..., 0.9]). (5 points)\n",
    "*Hint: A convenience function for plotting results is provided for you.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(db_size, noises, private_results, true_results):\n",
    "    # plots the results on varying noise levels on a specific database size\n",
    "\n",
    "    plt.scatter(noises, private_results, color = \"blue\", label = \"With Noise\")\n",
    "    plt.scatter(noises, true_results, color = \"red\", label = \"Without Noise\")\n",
    "    \n",
    "    plt.xlabel(\"Noise\")\n",
    "    plt.ylabel(\"Results\")\n",
    "    plt.title(\"DB Size : \" + str(db_size))\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nJ76qxNr7c11",
    "outputId": "cb55a376-8fee-4238-e3a2-62e8fd72aafd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYShe_kWDoX5"
   },
   "source": [
    "## The Formal Definition of Differential Privacy\n",
    "\n",
    "The previous method of adding noise was called \"Local Differential Privacy\" because we added noise to each data point individually. This is necessary for some situations wherein the data is so sensitive that individuals do not trust noise to be added later. However, it comes at a very high cost in terms of accuracy.\n",
    "\n",
    "However, alternatively, we can add noise after a function has aggregated data. This kind of noise can allow for similar levels of protection with a lower effect on accuracy. However, participants must be able to trust that no one looked at their data points before the aggregation took place. In some situations, this works out well, but it is less realistic in others (such as an individual hand-surveying a group of people).\n",
    "\n",
    "Nevertheless, global differential privacy is incredibly important because it allows us to perform differential privacy on smaller groups of individuals with lower amounts of noise. Let's revisit our sum functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "995NcC99EiVs",
    "outputId": "79f83543-f65a-466d-c19a-6ad99d7d304a"
   },
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "\n",
    "def query(db):\n",
    "    return torch.sum(db.float())\n",
    "\n",
    "def M(db):\n",
    "    query(db) + noise\n",
    "\n",
    "query(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atL-J0V7Es7e"
   },
   "source": [
    "The idea here is that we want to add noise to the output of our function. We can add two different kinds of noise - Laplacian Noise and Gaussian Noise. However, before we do so, we need to dive into the formal definition of Differential Privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zbai8k1vKaE7"
   },
   "source": [
    "### Epsilon\n",
    "Let's unpack the intuition of this for a moment.\n",
    "\n",
    "**Epsilon Zero**: If a query satisfied this inequality where epsilon was set to 0, then that would mean that the query for all parallel databases outputs the same value as the full database. \n",
    "\n",
    "**Epsilon One**: If a query satisfied this inequality with epsilon 1, then the maximum distance between all queries would be 1 - or more precisely - the maximum distance between the two random distributions M(x) and M(y) is 1 (because all these queries have some amount of randomness in them, just like we observed in the last section).\n",
    "\n",
    "### Delta\n",
    "\n",
    "Delta is the probability that epsilon breaks. Namely, sometimes the epsilon is different for some queries than others. \n",
    "\n",
    "## How To Add Noise for Global Differential Privacy\n",
    "\n",
    "Let's learn how to take a query and add varying amounts of noise to satisfy a certain degree of differential privacy. In particular, we will leave behind the previously discussed Local Differential privacy and instead focus on Global differential privacy.\n",
    "\n",
    "To sum up, this is about adding noise to our query's output to satisfy a certain epsilon-delta differential privacy threshold.\n",
    "\n",
    "We can add two kinds of noise - Gaussian Noise and Laplacian Noise. Generally speaking, Laplacian is better, but both are still valid. \n",
    "\n",
    "How much noise should we add?\n",
    "The amount of noise necessary to add to the output of a query is a function of four things:\n",
    "1. the type of noise (Gaussian/Laplacian)\n",
    "2. the sensitivity of the query/function\n",
    "3. the desired epsilon (ε)\n",
    "4. the desired delta (δ)\n",
    "\n",
    "Laplacian noise is increased/decreased according to a \"scale\" parameter b. We choose \"b\" based on the following formula.\n",
    "\n",
    "b = sensitivity(query) / epsilon\n",
    "\n",
    "In other words, if we set b to be this value, we know we will have a privacy leakage <= epsilon. Furthermore, the nice thing about Laplace is that it guarantees this with delta == 0. However, we can tune the parameters such that we have very low epsilon where the delta is non-zero, but we'll ignore them for now.\n",
    "\n",
    "If we query the database multiple times - we can add the epsilons (even if we change the amount of noise and their epsilons are not the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSynwpjnONRZ"
   },
   "source": [
    "## Create a Differentially Private Query\n",
    "\n",
    "Let's create a query function that sums over the database and adds just the right amount of noise to satisfy an epsilon constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91mr9BS3OZu6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epsilon = 0.0001\n",
    "\n",
    "db, pdbs = create_db_and_parallels(100)\n",
    "\n",
    "def sum_query(db):\n",
    "    return db.sum()\n",
    "\n",
    "def mean_query(db):\n",
    "    return torch.mean(db.float())\n",
    "\n",
    "def laplacian_mechanism(db, query, sensitivity):\n",
    "    \n",
    "    beta = sensitivity / epsilon\n",
    "    noise = torch.tensor(np.random.laplace(0, beta, 1))\n",
    "    \n",
    "    return query(db) + noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zifNq2BtOG2o",
    "outputId": "255a0fdc-4fb8-4dc3-a116-9436331d1f6f"
   },
   "outputs": [],
   "source": [
    "laplacian_mechanism(db, sum_query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kXcNAkW0O0Zy",
    "outputId": "92c13a6f-978d-414e-cb7a-03e2f59bde83"
   },
   "outputs": [],
   "source": [
    "laplacian_mechanism(db, mean_query, 1/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlURPqV8O-Ux"
   },
   "source": [
    "# Differential Privacy for Deep Learning\n",
    "\n",
    "## An Example Scenario: A Health Neural Network\n",
    "\n",
    "Let's consider a scenario - you work for a hospital and have a large collection of images of your patients. However, you do not know what's in them. You would like to use these images to develop a neural network to classify them automatically. However, since your images aren't labeled, they aren't sufficient to train a classifier.\n",
    "\n",
    "However, you realize you can reach out to 10 partner hospitals with annotated data. You plan to train your new classifier on their datasets so that you can automatically label your own. While these hospitals are interested in helping, they have privacy concerns regarding patient information. Thus, you will use the following technique to train a classifier that protects patients' privacy in the other hospitals.\n",
    "\n",
    "1. You ask each of the 10 hospitals to train a model on their datasets (all of which have the same labels).\n",
    "2. Use each of the 10 partner models on your local dataset, generating 10 labels for each of your data points.\n",
    "3. For each local data point (now with 10 labels), you perform a DP query to generate the final true label. This query is a \"max\" function, where \"max\" is the most frequent label across the 10 labels. You need to add laplacian noise to make this \"Differentially Private\" to a certain epsilon/delta constraint.\n",
    "4. Finally, you retrain a new model on your local dataset, which now has labels. This trained model will be our final \"Differentially Private\" model.\n",
    "\n",
    "Assuming you're already familiar with how to train/predict a deep neural network, we'll skip steps 1 and 2 and work with example data. We'll focus instead on step 3, namely how to perform the DP query for each example using toy data.\n",
    "\n",
    "So, let's say we have 10,000 training examples, and we've got 10 labels for each example (from our 10 \"teacher models,\" which were trained directly on private data). Each label is chosen from 10 possible labels (categories) for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VHw1KI2ZpBZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_teachers = 10 # we're working with 10 partner hospitals\n",
    "num_examples = 10000 # the size of OUR dataset\n",
    "num_labels = 10 # number of lablels for our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-WpqqnUDc88O",
    "outputId": "0bc510c8-df17-4183-896a-b08e692bf30c"
   },
   "outputs": [],
   "source": [
    "preds = (np.random.rand(num_teachers, num_examples) * num_labels).astype(int).transpose(1,0) # fake predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QblGI2fgdmXB"
   },
   "source": [
    "Prediction for the first data item from all the teachers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TpHEt0XydVrM",
    "outputId": "e4a40444-3eb0-4d70-a966-72f88a06dccc"
   },
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNEssMDKdg8d"
   },
   "source": [
    "All the predictions from the first teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gODrmYyRdYLe",
    "outputId": "c66b288e-fe6e-4af8-f331-821710f5f5c2"
   },
   "outputs": [],
   "source": [
    "preds[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCoooxS7dyZv"
   },
   "source": [
    "### Task 6: Combine these label predictions in a differentially private way. You may use an epsilon value of 0.1. (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning\n",
    "\n",
    "Federated Learning is a machine learning technique that allows multiple clients to collaborate on a model training task without sharing their data with a central server. Instead, the clients train their models locally and exchange model updates with each other or with a central aggregator to improve the global model.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By completing this part of the lab, you will learn:\n",
    "\n",
    "* How to use PyTorch to implement a federated learning algorithm\n",
    "* How to distribute the training process across multiple clients\n",
    "* How to aggregate model weights from multiple clients to improve the global model performance\n",
    "* How to evaluate the performance of a federated learning algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment\n",
    "\n",
    "We start by installing the required packages and importing the necessary modules.\n",
    "It is highly recommended that you check out the [FedLab GitHub](https://github.com/SMILELab-FL/FedLab) repo and use the code directly from there.\n",
    "Alternatively, using the following command, you can install fedlab and torchvision.\n",
    "\n",
    "Reference: Tutorial for FedLab users (https://github.com/SMILELab-FL/FedLab/blob/master/tutorials/pipeline_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fedlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you clone the FedLab GitHub repo, here's an example code snippet on how you may configure your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"../\")\n",
    "\n",
    "# configuration\n",
    "from munch import Munch\n",
    "from fedlab.models.mlp import MLP\n",
    "\n",
    "from fedlab.utils.functional import evaluate\n",
    "from fedlab.core.standalone import StandalonePipeline\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Load the MNIST dataset [3 points]\n",
    "\n",
    "You will be using the MNIST dataset for this lab. You may load the dataset using the TorchVision API or use Fedlab's version of the dataset.\n",
    "FedLab provides the necessary module for users to partition their datasets. Additionally, various implementations of datasets partition for federated learning are available at the [URL](https://github.com/SMILELab-FL/FedLab/tree/master/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you load the dataset, you may use the following function to visualize the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28\n",
    "\n",
    "def show_data(data_sample):\n",
    "    \"\"\"plot out data samples as images\"\"\"\n",
    "    plt.imshow(data_sample[0].numpy().reshape(\n",
    "        IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Visualize a single digit [2 points]\n",
    "\n",
    "Using the above function, visualize any digit in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Define the model architecture [5 points]\n",
    "You should use PyTorch and the FedLab APIs to define your model architecture. \n",
    "\n",
    "*Hint: You can use a simple neural network or the `fedlab.models.mlp`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Implement the client-side training logic [5 points]\n",
    "\n",
    "Implement the client-side training logic, which should involve loading the local data, training the model on the local data, and sending the updated weights to the server. \n",
    "\n",
    "*Hint: For this task, you may use the `fedlab.contrib.algorithm.basic_client`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11: Implement the server-side aggregation logic [5 points]\n",
    "\n",
    "Implement the server-side aggregation logic, which should involve receiving the updated weights from each client, aggregating the weights, and sending the updated global model weights back to each client. \n",
    "\n",
    "*Hint: You may use the `fedlab.contrib.algorithm.basic_server`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: Train the federated learning algorithm [5 points]\n",
    "\n",
    "Once you have implemented the client-side training and server-side aggregation logic, you should train the model. \n",
    "\n",
    "*Hint: We recommend creating a subclass of the `fedlab.core.standalone.StandalonePipeline` for this purpose.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13: Evaluate the federated learning algorithm [5 points]\n",
    "\n",
    "Now, evaluate the performance of the federated learning algorithm. You can do this by computing the accuracy of the global model on the test set. You can also compare the performance of the federated learning algorithm with that of a centralized learning algorithm, where the data is collected and trained on a single server.\n",
    "\n",
    "Use the convenience functions below for your evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generate_loss_accuracy_charts(label, loss_list,  accuracy_list):\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # create a subplot for the current key\n",
    "    # ax = fig.add_subplot(len(data1), 1, i+1)\n",
    "\n",
    "    color = 'tab:green'\n",
    "    ax1.set_xlabel('epoch', color=color)\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(loss_list, color=color)\n",
    "    ax1.set_ylabel('total loss', color=color)\n",
    "    ax1.tick_params(axis='y', color=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color=color)\n",
    "    ax2.plot(accuracy_list, color=color)\n",
    "    ax2.tick_params(axis='y', color=color)\n",
    "\n",
    "    ax1.set_title(label)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # show the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your analysis, you could analyze misclassified images using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_first_five_misclassified_samples(dataset, model):\n",
    "    Softmax_fn = nn.Softmax(dim=-1)\n",
    "    count = 0\n",
    "    for x, y in dataset:\n",
    "        z = model(x.unsqueeze(0))\n",
    "        _, yhat = torch.max(z, 1)\n",
    "        if yhat != y:\n",
    "            show_data((x, y))\n",
    "            plt.show()\n",
    "            print(\"yhat:\", yhat)\n",
    "            print(\"probability of class \", torch.max(Softmax_fn(z)).item())\n",
    "            count += 1\n",
    "        if count >= 5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14: Fine-tune the hyperparameters [5 points]\n",
    "\n",
    "You should experiment with different hyperparameters to improve the performance of the federated learning algorithm. \n",
    "\n",
    "*Hint: You can try adjusting the num clients, learning rate, the batch size, or the number of communication rounds.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 15: A description of the federated learning algorithm you implemented. [5 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here (this is a written answer, use markdown syntax as necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 16: A summary of the performance of the federated learning algorithm [5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here (this is a written answer, use markdown syntax as necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 17: A comparison of the performance of the federated learning algorithm with the performance of a centralized learning algorithm [5 points]\n",
    "\n",
    "*Hint: To implement centralized training you set num client to be 1 and try out a few different learning rates.*\n",
    "\n",
    "*Hint: You must also provide a written answer in markdown syntax analyzing the results you obtained.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here (this is a written answer, use markdown syntax as necessary).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 18: A discussion of the hyperparameters you fine-tuned and their impact on the performance of the federated learning algorithm [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type any supporting code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here (this is a written answer, use markdown syntax as necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 19: Implement the aggregator using a Solidity smart contract. [10 points]\n",
    "You must write Solidity code to get full points for this question. The contract should be syntactically correct (i.e., compile).\n",
    "\n",
    "Some Hints: \n",
    "* Create structs for the Participants (i.e., clients) and Global Model (i.e., the server). \n",
    "* Some useful functions to include in the smart contract: addParticipant, updateParticipantParameters, aggregate\n",
    "* The `aggregate` function should aggregate the model parameters from all the participants, and you are welcome to utilize any relevant algorithm for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the code is in Solidity, place it inside the markdown cell in the \"javascript\" environment.\n",
    "\n",
    "```javascript\n",
    "//Type your code here. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 20: Deploying and using the aggregator smart contract. [5 points]\n",
    "Please describe the steps you would take to deploy the smart contract you developed above on an Ethereum test network (you need not deploy the contract). How would the participants/clients interact with the smart contract?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here (this is a written answer, use markdown syntax as necessary)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "secure_private_AI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1fe8e4d96a285da23bbd9adf1624e7f8c0742471a586e45e4d4ad444ea6dadb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
